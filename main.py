import os
import csv
import json
import hashlib
import sys
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional

import requests
from requests.adapters import HTTPAdapter

# --- ç±»å‹å®šä¹‰ä¸æ•°æ®ç±» ---
@dataclass
class Config:
    """åº”ç”¨ç¨‹åºçš„å…¨å±€é…ç½®"""
    repo_name: Optional[str] = None
    config_file: Path = Path("config.csv")
    icon_assets_dir: Path = Path("icons/assets")
    all_in_one_json: Path = Path("icons/allinone.json")
    update_log_file: Path = Path("update.log")
    commit_message_file: Path = Path("commit_message.txt")
    github_event_name: Optional[str] = os.getenv("GITHUB_EVENT_NAME")

    @property
    def base_cdn_url(self) -> str:
        """æ ¹æ®ä»“åº“åç§°åŠ¨æ€ç”ŸæˆCDNåŸºç¡€URL"""
        if self.repo_name:
            return f"https://cdn.jsdelivr.net/gh/{self.repo_name}@main/"
        return ""

@dataclass
class SourceConfig:
    """ä»£è¡¨ config.csv ä¸­çš„ä¸€ä¸ªæº"""
    comment: str
    src_url: str
    path: Path
    author: str

@dataclass
class IconData:
    """ä»£è¡¨ä¸€ä¸ªå¾…å¤„ç†çš„å›¾æ ‡æ¡ç›®"""
    name: str
    url: str
    author: str
    source: str
    original_name: str

@dataclass
class ProcessResult:
    """ä»£è¡¨ä¸€ä¸ªå·²æˆåŠŸå¤„ç†çš„å›¾æ ‡ç»“æœ"""
    primary: IconData
    md5: str
    size: int
    filepath: Path
    original_url: str

# --- å…¨å±€å¸¸é‡ ---
MIME_TO_EXT = {
    "image/png": "png",  "image/jpeg": "jpg",
    "image/gif": "gif",  "image/webp": "webp",
    "image/svg+xml": "svg",
}

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
def get_session() -> requests.Session:
    """åˆ›å»ºä¸€ä¸ªå¸¦æœ‰é‡è¯•æœºåˆ¶çš„ requests.Session"""
    session = requests.Session()
    adapter = HTTPAdapter(pool_connections=100,
                          pool_maxsize=100, max_retries=3)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

def setup_environment(config: Config):
    """åˆ›å»ºå¿…è¦çš„ç›®å½•å¹¶æ¸…ç†æ—§çš„æ—¥å¿—æ–‡ä»¶"""
    config.icon_assets_dir.mkdir(parents=True, exist_ok=True)
    if config.update_log_file.exists():
        config.update_log_file.unlink()
    if config.commit_message_file.exists():
        config.commit_message_file.unlink()

def parse_arguments() -> Config:
    """è§£æå‘½ä»¤è¡Œå‚æ•°ä»¥æ„å»ºé…ç½®å¯¹è±¡"""
    repo_name = sys.argv[1] if len(sys.argv) > 1 and sys.argv[1] else None
    config = Config(repo_name=repo_name)

    if config.base_cdn_url:
        print(f"âœ… CDN åŸºç¡€URLå·²é…ç½®: {config.base_cdn_url}")
    else:
        print("âš ï¸ è­¦å‘Š: æœªæä¾›GitHubä»“åº“åç§°ã€‚å°†ä½¿ç”¨ç›¸å¯¹è·¯å¾„ç”ŸæˆURLã€‚", file=sys.stderr)
    return config

def load_sources_from_csv(config_file: Path) -> List[SourceConfig]:
    """ä»CSVé…ç½®æ–‡ä»¶ä¸­åŠ è½½æ‰€æœ‰å›¾æ ‡æº"""
    sources = []
    if not config_file.is_file():
        print(f"â é”™è¯¯: é…ç½®æ–‡ä»¶ '{config_file}' æœªæ‰¾åˆ°ï¼", file=sys.stderr)
        sys.exit(1)

    with config_file.open("r", encoding="utf-8") as f:
        reader = csv.reader(
            filter(lambda row: row and not row[0].strip().startswith('#'), f))
        for row in reader:
            if len(row) < 3:
                continue
            comment, src_url, path_str = [item.strip() for item in row]
            author = Path(path_str).name.split("_")[0]
            sources.append(SourceConfig(
                comment=comment, src_url=src_url, path=Path(path_str), author=author
            ))
    return sources

def fetch_upstream_icons(sources: List[SourceConfig], session: requests.Session) -> Tuple[List[IconData], Dict[Path, Dict]]:
    """ä»æ‰€æœ‰ä¸Šæ¸¸æºè·å–å›¾æ ‡å®šä¹‰"""
    all_icons_to_process = []
    source_jsons = {}
    print("\nğŸ”„ (1/4) è§£æé…ç½®æ–‡ä»¶, æ”¶é›†ä¸Šæ¸¸æœ€æ–°å›¾æ ‡...")
    for source in sources:
        print(f"  - å¤„ç†æº: {source.comment}")
        try:
            resp = session.get(source.src_url, timeout=10)
            resp.raise_for_status()
            source_json = resp.json()
            source_jsons[source.path] = source_json

            for icon in source_json.get("icons", []):
                if icon.get("name") and icon.get("url"):
                    all_icons_to_process.append(IconData(
                        name=icon["name"], url=icon["url"], author=source.author,
                        source=source.comment, original_name=f"{icon['name']}-{source.author}"
                    ))
        except requests.exceptions.RequestException as e:
            print(
                f"  - è­¦å‘Š: ç½‘ç»œè¯·æ±‚å¤±è´¥ '{source.comment}'. URL: {source.src_url}", file=sys.stderr)
        except json.JSONDecodeError as e:
            print(
                f"  - è­¦å‘Š: JSONè§£æå¤±è´¥ '{source.comment}'. URL: {source.src_url}", file=sys.stderr)
    return all_icons_to_process, source_jsons

def process_icon_entry(session: requests.Session, icon_data: IconData, assets_dir: Path) -> Optional[ProcessResult]:
    """ä¸‹è½½ã€å¤„ç†å•ä¸ªå›¾æ ‡ï¼Œå¹¶è¿”å›å…¶å…ƒæ•°æ®"""
    try:
        response = session.get(icon_data.url, timeout=20, stream=True)
        response.raise_for_status()
        content = response.content
        if not content:
            print(f"  - è­¦å‘Š: ä¸‹è½½å†…å®¹ä¸ºç©º. URL: {icon_data.url}", file=sys.stderr)
            return None

        mime_type = response.headers.get(
            "Content-Type", "").split(";")[0].strip()
        ext = MIME_TO_EXT.get(mime_type)
        if not ext:
            print(
                f"  - è­¦å‘Š: ä¸æ”¯æŒçš„ MIME ç±»å‹ '{mime_type}'. URL: {icon_data.url}", file=sys.stderr)
            return None

        md5_hash = hashlib.md5(content).hexdigest()
        new_filepath = assets_dir / f"{md5_hash}.{ext}"
        if not new_filepath.exists():
            new_filepath.write_bytes(content)

        return ProcessResult(
            primary=icon_data, md5=md5_hash, size=len(content),
            filepath=new_filepath, original_url=icon_data.url
        )
    except requests.exceptions.RequestException:
        print(f"  - é”™è¯¯: ä¸‹è½½å¤±è´¥. URL: {icon_data.url}", file=sys.stderr)
        return None

def process_icons_concurrently(icons: List[IconData], assets_dir: Path) -> List[ProcessResult]:
    """ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ‰€æœ‰å›¾æ ‡"""
    total = len(icons)
    print(f"\nğŸ“Š (2/4) æ”¶é›†å®Œæˆ, å…± {total} æ¡ç›®. å¼€å§‹å¹¶å‘å¤„ç†...")
    results = []
    with ThreadPoolExecutor(max_workers=os.cpu_count() * 2) as executor:
        session = get_session()
        futures = {executor.submit(
            process_icon_entry, session, icon, assets_dir): icon for icon in icons}
        for future in as_completed(futures):
            result = future.result()
            if result:
                results.append(result)
    print(f"  - æœ¬åœ°åŒ–å¤„ç†å®Œæˆ. æˆåŠŸå¤„ç† {len(results)} / {total} ä¸ªå›¾æ ‡ã€‚")
    return results

def update_allinone_json(results: List[ProcessResult], sources: List[SourceConfig], config: Config) -> Tuple[Dict[str, str], List[Dict]]:
    """èšåˆç»“æœã€æ›´æ–° allinone.json å¹¶è¿”å› URL æ˜ å°„å’Œæ–°å¢å›¾æ ‡åˆ—è¡¨"""
    print(f"\nâš’ï¸ (3/4) å½’æ¡£å¼èšåˆç»“æœä»¥ç”Ÿæˆ '{config.all_in_one_json}'...")

    url_map, md5_map = {}, {}
    for res in results:
        final_url = f"{config.base_cdn_url}{res.filepath.as_posix()}"
        url_map[res.original_url] = final_url
        if res.md5 not in md5_map:
            md5_map[res.md5] = {"primary": res.primary,
                                "aliases": [], "url": final_url, "size": res.size}
        else:
            md5_map[res.md5]["aliases"].append(res.primary)

    new_normalized_icons = []
    for md5, data in md5_map.items():
        primary: IconData = data["primary"]
        description = f"æ¥æº: {primary.source}"
        if data['aliases']:
            description += f" | åˆ«å: {', '.join(alias.original_name for alias in data['aliases'])}"
        new_normalized_icons.append(
            {"md5": md5, "name": primary.name, "url": data["url"], "size": data["size"], "description": description})

    old_icons = []
    if config.all_in_one_json.exists() and config.all_in_one_json.stat().st_size > 0:
        try:
            old_icons = json.loads(config.all_in_one_json.read_text(
                encoding="utf-8")).get("icons", [])
        except json.JSONDecodeError:
            print(f"  - è­¦å‘Š: '{config.all_in_one_json}' æ–‡ä»¶æŸåï¼Œå°†é‡æ–°åˆ›å»ºã€‚")

    old_count = len(old_icons)
    all_icons_map = {icon['url']: icon for icon in old_icons}
    all_icons_map.update({icon['url']: icon for icon in new_normalized_icons})
    final_icons_list = sorted(all_icons_map.values(), key=lambda x: (
        x['name'].lower(), -x.get('size', 0)))
    final_count = len(final_icons_list)

    newly_added = []
    if final_count > old_count:
        print(
            f"  - æ£€æµ‹åˆ°æ–°å¢å›¾æ ‡ï¼å°†æ›´æ–° '{config.all_in_one_json}'ã€‚ æ—§: {old_count}, æ–°: {final_count}")
        old_urls = {icon['url'] for icon in old_icons}
        newly_added = [
            icon for icon in final_icons_list if icon['url'] not in old_urls]
        if newly_added:
            log_lines = [
                f'"{icon["md5"]}": {icon["name"]}' for icon in newly_added]
            config.update_log_file.write_text(
                "\n".join(log_lines), encoding="utf-8")

        all_authors = ", ".join(sorted(list(set(s.author for s in sources))))
        final_json = {"name": "Emby Icons",
                      "description": f"åŒ…å«æ¥è‡ª {all_authors} çš„ä½œå“ã€‚å½“å‰å…±æ”¶å½• {final_count} ä¸ªç‹¬ç«‹å›¾æ ‡ã€‚", "icons": final_icons_list}
        config.all_in_one_json.write_text(json.dumps(
            final_json, indent=2, ensure_ascii=False), encoding="utf-8")
        print(f"  - æˆåŠŸç”Ÿæˆå½’æ¡£æ–‡ä»¶ '{config.all_in_one_json}'ï¼")
    else:
        print(
            f"  - å›¾æ ‡åº“å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–° '{config.all_in_one_json}'ã€‚å›¾æ ‡æ•°é‡: {final_count}")

    return url_map, newly_added

def generate_commit_message(newly_added: List[Dict], config: Config):
    """æ ¹æ®æ›´æ–°ç»“æœç”Ÿæˆæäº¤ä¿¡æ¯å¹¶å†™å…¥æ–‡ä»¶"""
    print(f"  - ç”Ÿæˆæäº¤ä¿¡æ¯...")
    commit_msg_lines = []
    if newly_added:
        icon_count = len(newly_added)
        commit_msg_subject = f"feat: æ–°å¢ {icon_count} ä¸ªå›¾æ ‡"
        commit_msg_lines.append(commit_msg_subject)
        commit_msg_lines.append("")
        commit_msg_lines.append(f"å°† {icon_count} ä¸ªæ–°å›¾æ ‡æ·»åŠ åˆ° allinone.jsonã€‚")
        commit_msg_lines.append("")
        commit_msg_lines.append("æ–°å¢å›¾æ ‡åˆ—è¡¨ (æœ€å¤šæ˜¾ç¤º10ä¸ª):")
        for icon in newly_added[:10]:
            commit_msg_lines.append(f"  - {icon['name']}")
        
        if icon_count > 10:
            commit_msg_lines.append(f"... åŠå…¶ä»– {icon_count - 10} ä¸ªã€‚")
    else:
        event_name = config.github_event_name
        if event_name == "schedule":
            commit_msg_subject = "chore(Scheduled): åŒæ­¥ä¸Šæ¸¸å›¾æ ‡åº“"
        elif event_name == "workflow_dispatch":
            commit_msg_subject = "chore(Manual): åŒæ­¥ä¸Šæ¸¸å›¾æ ‡åº“"
        else:
            commit_msg_subject = "chore(Auto): åŒæ­¥ä¸Šæ¸¸å›¾æ ‡åº“"
        commit_msg_lines.append(commit_msg_subject)
        commit_msg_lines.append("")
        commit_msg_lines.append("ä¾‹è¡Œæ›´æ–°ï¼Œæœªæ£€æµ‹åˆ°æ–°å¢å›¾æ ‡ã€‚")

    commit_msg_lines.append("")
    commit_msg_lines.append(f"æ›´æ–°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S %Z')}")
    
    config.commit_message_file.write_text("\n".join(commit_msg_lines), encoding="utf-8")
    print(f"  - æäº¤ä¿¡æ¯å·²ç”Ÿæˆåˆ° '{config.commit_message_file}'")

def rewrite_source_json_files(sources: List[SourceConfig], source_jsons: Dict[Path, Dict], url_map: Dict[str, str]):
    """ä½¿ç”¨CDN URLé‡å†™å„ä¸ªç‹¬ç«‹çš„JSONé…ç½®æ–‡ä»¶"""
    print(f"\nâœï¸ (4/4) å¼€å§‹é•œåƒå¼é‡å†™å„ç‹¬ç«‹çš„JSONé…ç½®æ–‡ä»¶...")
    for source in sources:
        if source.path not in source_jsons:
            continue

        print(f"  - é‡å†™: {source.path}")
        content = source_jsons[source.path].copy()
        content["name"] = f"{source.comment} (CDNé•œåƒç‰ˆ)"
        content["description"] = f"æºè‡ª: {source.src_url}"
        content["icons"] = [{**icon, "url": url_map.get(icon.get("url"), icon.get(
            "url"))} for icon in content.get("icons", []) if icon.get("url")]
        source.path.write_text(json.dumps(
            content, indent=2, ensure_ascii=False), encoding="utf-8")

def main():
    """è„šæœ¬ä¸»å…¥å£ï¼Œè´Ÿè´£ç¼–æ’æ•´ä¸ªæµç¨‹"""
    start_time = time.time()
    config = parse_arguments()
    setup_environment(config)
    sources = load_sources_from_csv(config.config_file)
    session = get_session()
    icons_to_process, source_jsons = fetch_upstream_icons(sources, session)
    processed_results = process_icons_concurrently(
        icons_to_process, config.icon_assets_dir)
    url_map, newly_added = update_allinone_json(processed_results, sources, config)
    generate_commit_message(newly_added, config)
    rewrite_source_json_files(sources, source_jsons, url_map)
    print(f"\nğŸ‰ å…¨éƒ¨ä»»åŠ¡å®Œæˆï¼æ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’ã€‚")

if __name__ == "__main__":
    main()
